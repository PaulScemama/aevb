{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pscemama/aevb/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "from datasets import load_dataset\n",
    "import jax.random as random\n",
    "from jax.random import PRNGKey, split\n",
    "\n",
    "from aevb.core import AEVB\n",
    "\n",
    "\n",
    "# Data Processing Functions ----------------------------------\n",
    "def one_hot_encode(x, k):\n",
    "    \"Create a one-hot encoding of x of size k.\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype=jnp.float32)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def prepare_data(X):\n",
    "    num_examples = X.shape[0]\n",
    "    num_pixels = 28 * 28\n",
    "    X = X.reshape(num_examples, num_pixels)\n",
    "    X = X / 255.0\n",
    "\n",
    "    return X, num_examples\n",
    "\n",
    "\n",
    "def data_stream(seed, data, batch_size, data_size):\n",
    "    \"\"\"Return an iterator over batches of data.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    num_batches = int(jnp.ceil(data_size / batch_size))\n",
    "    while True:\n",
    "        perm = rng.permutation(data_size)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i * batch_size : (i + 1) * batch_size]\n",
    "            yield data[batch_idx]\n",
    "\n",
    "\n",
    "# Generative Model and Recognition Feature Extractor --------------------\n",
    "# class GenModel(eq.Module):\n",
    "#     @nn.compact\n",
    "#     def __call__(self, x, train: bool = False):\n",
    "#         x = nn.Dense(features=128)(x)\n",
    "#         x = nn.BatchNorm(use_running_average=not train)(x)\n",
    "#         x = nn.relu(x)\n",
    "#         x = nn.Dense(features=256)(x)\n",
    "#         x = nn.relu(x)\n",
    "#         x = nn.Dense(784)(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class RecModel(nn.Module):\n",
    "#     latent_dim: int\n",
    "\n",
    "#     @nn.compact\n",
    "#     def __call__(self, x, train: bool = False):\n",
    "#         x = nn.Dense(features=512)(x)\n",
    "#         x = nn.BatchNorm(use_running_average=not train)(x)\n",
    "#         x = nn.relu(x)\n",
    "#         x = nn.Dense(features=256)(x)\n",
    "#         x = nn.relu(x)\n",
    "#         x = nn.Dense(features=128)(x)\n",
    "#         x = nn.relu(x)\n",
    "#         x = nn.Dense(features=64)(x)\n",
    "#         z_mu = nn.Dense(features=self.latent_dim)(x)\n",
    "#         z_logvar = nn.Dense(features=self.latent_dim)(x)\n",
    "#         z_sigma = jnp.exp(z_logvar * 0.5)\n",
    "#         return z_mu, z_sigma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpEncoder(eqx.Module):\n",
    "    #spectral_linear: eqx.nn.SpectralNorm[eqx.nn.Linear]\n",
    "    linear1: eqx.nn.Linear\n",
    "    linear2: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, key):\n",
    "        key1, key2, key3, key4 = random.split(key, 4)\n",
    "        #self.norm1 = eqx.nn.BatchNorm(input_size=3, axis_name=\"batch\")\n",
    "        # self.spectral_linear = eqx.nn.SpectralNorm(\n",
    "        #     layer=eqx.nn.Linear(in_features=3, out_features=32, key=key1),\n",
    "        #     weight_name=\"weight\",\n",
    "        #     key=key2,\n",
    "        # )\n",
    "        #self.norm2 = eqx.nn.BatchNorm(input_size=32, axis_name=\"batch\")\n",
    "        self.linear1 = eqx.nn.Linear(in_features=10, out_features=32, key=key3)\n",
    "        self.linear2 = eqx.nn.Linear(in_features=32, out_features=3, key=key4)\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        #x, state = self.norm1(x, state)\n",
    "        #x, state = self.spectral_linear(x, state)\n",
    "        x = jax.nn.relu(x)\n",
    "        #x, state = self.norm2(x, state)\n",
    "        x = self.linear1(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, state\n",
    "\n",
    "\n",
    "class MlpDecoder(eqx.Module):\n",
    "    #spectral_linear: eqx.nn.SpectralNorm[eqx.nn.Linear]\n",
    "    linear1: eqx.nn.Linear\n",
    "    linear2: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, key):\n",
    "        key1, key2, key3, key4 = random.split(key, 4)\n",
    "        #self.norm1 = eqx.nn.BatchNorm(input_size=3, axis_name=\"batch\")\n",
    "        # self.spectral_linear = eqx.nn.SpectralNorm(\n",
    "        #     layer=eqx.nn.Linear(in_features=3, out_features=32, key=key1),\n",
    "        #     weight_name=\"weight\",\n",
    "        #     key=key2,\n",
    "\n",
    "        #self.norm2 = eqx.nn.BatchNorm(input_size=32, axis_name=\"batch\")\n",
    "        self.linear1 = eqx.nn.Linear(in_features=3, out_features=8, key=key3)\n",
    "        self.linear2 = eqx.nn.Linear(in_features=8, out_features=10, key=key4)\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        #x, state = self.norm1(x, state)\n",
    "        #x, state = self.spectral_linear(x, state)\n",
    "        x = jax.nn.relu(x)\n",
    "        #x, state = self.norm2(x, state)\n",
    "        x = self.linear1(x)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, state\n",
    "\n",
    "from aevb.core import wrap_eqx_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 19:13:30.405629: W external/xla/xla/service/gpu/nvptx_compiler.cc:742] The NVIDIA driver's CUDA version is 12.0 which is older than the ptxas CUDA version (12.4.99). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m localtime, strftime\n\u001b[1;32m     56\u001b[0m now \u001b[38;5;241m=\u001b[39m strftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, localtime())\n\u001b[0;32m---> 57\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./samples-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnow\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(save_samples_pth)\u001b[0m\n\u001b[1;32m     17\u001b[0m latent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39madam(\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m init, step, sample_data \u001b[38;5;241m=\u001b[39m \u001b[43mAEVB\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerative_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMlpEncoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecognition_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMlpDecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnn_lib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mequinox\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Run AEVB\u001b[39;00m\n\u001b[1;32m     30\u001b[0m key \u001b[38;5;241m=\u001b[39m PRNGKey(\u001b[38;5;241m1242\u001b[39m)\n",
      "File \u001b[0;32m~/aevb/aevb/core.py:111\u001b[0m, in \u001b[0;36mAEVB\u001b[0;34m(latent_dim, generative_model, recognition_model, optimizer, n_samples, nn_lib)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m AEVBState(rec_params, rec_state, gen_params, gen_state, opt_state)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nn_lib \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequinox\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m     gen_init, gen_apply \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_eqx_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerative_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     rec_init, rec_apply \u001b[38;5;241m=\u001b[39m wrap_eqx_model(recognition_model)\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fn\u001b[39m(rng_key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AEVBState:\n",
      "File \u001b[0;32m~/aevb/aevb/core.py:39\u001b[0m, in \u001b[0;36mwrap_eqx_model\u001b[0;34m(eqx_model, **init_kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install equinox if you intend to use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Get `static` information from model for combining in `apply` later...\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m model, _ \u001b[38;5;241m=\u001b[39m \u001b[43meqx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_with_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43meqx_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m _, static \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mpartition(model, eqx\u001b[38;5;241m.\u001b[39mis_inexact_array)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit\u001b[39m(rng_key):\n",
      "File \u001b[0;32m~/aevb/.venv/lib/python3.11/site-packages/equinox/nn/_stateful.py:367\u001b[0m, in \u001b[0;36mmake_with_state.<locals>.make_with_state_impl\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_with_state_impl\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[_T, State]:\n\u001b[0;32m--> 367\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmake_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# Replace all markers with `int`s. This is needed to ensure that two calls\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;66;03m# to `make_with_state` produce compatible models and states.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m     leaves, treedef \u001b[38;5;241m=\u001b[39m jtu\u001b[38;5;241m.\u001b[39mtree_flatten(model, is_leaf\u001b[38;5;241m=\u001b[39m_is_index)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "# Main Function --------------------------------\n",
    "def main(save_samples_pth: str):\n",
    "\n",
    "    # Prepare Data\n",
    "    mnist_data = load_dataset(\"mnist\")\n",
    "    data_train = mnist_data[\"train\"]\n",
    "\n",
    "    X_train = np.stack([np.array(example[\"image\"]) for example in data_train])\n",
    "    X_train, N_train = prepare_data(X_train)\n",
    "\n",
    "    seed = 1\n",
    "    n = N_train.item()\n",
    "    batch_size = 100\n",
    "    batches = data_stream(seed, X_train, batch_size, n)\n",
    "\n",
    "    # Create AEVB inference engine\n",
    "    latent_dim = 3\n",
    "    optimizer = optax.adam(1e-3)\n",
    "\n",
    "    init, step, sample_data = AEVB(\n",
    "        latent_dim=latent_dim,\n",
    "        generative_model=(MlpEncoder, {}),\n",
    "        recognition_model=(MlpDecoder, {}),\n",
    "        optimizer=optimizer,\n",
    "        n_samples=15,\n",
    "        nn_lib=\"equinox\",\n",
    "    )\n",
    "\n",
    "    # Run AEVB\n",
    "    key = PRNGKey(1242)\n",
    "    num_steps = 10000\n",
    "    eval_every = 100\n",
    "\n",
    "    key, init_key = split(key)\n",
    "    state = init(init_key, X_train.shape[-1])\n",
    "\n",
    "    key, *training_keys = split(key, num_steps + 1)\n",
    "    for i, rng_key in enumerate(training_keys):\n",
    "        batch = next(batches)\n",
    "        state, info = step(rng_key, state, batch)\n",
    "        if i % eval_every == 0:\n",
    "            print(f\"Step {i} | loss: {info.loss} | nll: {info.nll} | kl: {info.kl}\")\n",
    "\n",
    "    # Random Data Samples of Learned Generative Model\n",
    "    key, data_samples_key = split(key)\n",
    "    samples, _ = sample_data(data_samples_key, state.gen_params, state.gen_state, 5)\n",
    "    fig, axs = plt.subplots(5, 1)\n",
    "    for i, s in enumerate(samples):\n",
    "        axs[i].imshow(s.reshape(28, 28))\n",
    "    plt.savefig(save_samples_pth, format=\"png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from time import localtime, strftime\n",
    "\n",
    "    now = strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n",
    "    main(f\"./samples-{now}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, {'2': 2})\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "def foo(x, **kwargs):\n",
    "    bar(x, **kwargs)\n",
    "\n",
    "def bar(x, **kwargs):\n",
    "    print(x)\n",
    "    print(kwargs)\n",
    "\n",
    "_in = (1, {\"2\": 2})\n",
    "foo(_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (2566220079.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    *_in\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
