{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pscemama/aevb/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "from datasets import load_dataset\n",
    "import jax.random as random\n",
    "from jax.random import PRNGKey, split\n",
    "\n",
    "from aevb.core import AEVB\n",
    "\n",
    "\n",
    "# Data Processing Functions ----------------------------------\n",
    "def one_hot_encode(x, k):\n",
    "    \"Create a one-hot encoding of x of size k.\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype=jnp.float32)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def prepare_data(X):\n",
    "    num_examples = X.shape[0]\n",
    "    num_pixels = 28 * 28\n",
    "    X = X.reshape(num_examples, num_pixels)\n",
    "    X = X / 255.0\n",
    "\n",
    "    return X, num_examples\n",
    "\n",
    "\n",
    "def data_stream(seed, data, batch_size, data_size):\n",
    "    \"\"\"Return an iterator over batches of data.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    num_batches = int(jnp.ceil(data_size / batch_size))\n",
    "    while True:\n",
    "        perm = rng.permutation(data_size)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i * batch_size : (i + 1) * batch_size]\n",
    "            yield data[batch_idx]\n",
    "\n",
    "\n",
    "class MlpEncoder(eqx.Module):\n",
    "    norm1: eqx.nn.BatchNorm\n",
    "    linear1: eqx.nn.Linear\n",
    "    linear2: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, key):\n",
    "        key1, key2 = random.split(key)\n",
    "        self.norm1 = eqx.nn.BatchNorm(input_size=32, axis_name=\"batch\")\n",
    "        self.linear1 = eqx.nn.Linear(in_features=10, out_features=32, key=key1)\n",
    "        self.linear2 = eqx.nn.Linear(in_features=32, out_features=3, key=key2)\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        x = self.linear1(x)\n",
    "        x, state = self.norm1(x, state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, state\n",
    "\n",
    "\n",
    "class MlpDecoder(eqx.Module):\n",
    "    norm1: eqx.nn.BatchNorm\n",
    "    linear1: eqx.nn.Linear\n",
    "    linear2: eqx.nn.Linear\n",
    "\n",
    "    def __init__(self, key):\n",
    "        key1, key2 = random.split(key)\n",
    "        self.norm1 = eqx.nn.BatchNorm(input_size=8, axis_name=\"batch\")\n",
    "        self.linear1 = eqx.nn.Linear(in_features=3, out_features=8, key=key1)\n",
    "        self.linear2 = eqx.nn.Linear(in_features=8, out_features=10, key=key2)\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        x = self.linear1(x)\n",
    "        x, state = self.norm1(x, state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 01:43:59.074849: W external/xla/xla/service/gpu/nvptx_compiler.cc:742] The NVIDIA driver's CUDA version is 12.0 which is older than the ptxas CUDA version (12.4.99). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "from aevb._src.eqx import convert_eqx_model\n",
    "init, apply = convert_eqx_model(MlpEncoder, random.key(0))\n",
    "\n",
    "rec_params, rec_state = init()\n",
    "model = apply(params=rec_params, state=rec_state, input=jnp.ones((100, 10)), train=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 3\n",
    "optimizer = optax.adam(1e-3)\n",
    "init, step, sample_data = AEVB(\n",
    "    latent_dim=latent_dim,\n",
    "    generative_model=(MlpDecoder, {\"rng_key\": random.key(0)}),\n",
    "    recognition_model=(MlpEncoder, {\"rng_key\": random.key(1)}),\n",
    "    optimizer=optimizer,\n",
    "    n_samples=15,\n",
    "    nn_lib=\"equinox\",\n",
    ")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m aevb_state \u001b[38;5;241m=\u001b[39m init()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aevb/aevb/_src/core.py:212\u001b[0m, in \u001b[0;36mAEVB.<locals>.step_fn\u001b[0;34m(rng_key, aevb_state, x)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;129m@jit\u001b[39m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_fn\u001b[39m(rng_key, aevb_state, x) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[AEVBState, AEVBInfo]:\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Take a step of Algorithm 1 from [1] using the second verison of the\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    SGVB estimator which takes advantage of an analytical KL term when the prior\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    p(z) is a unit normal.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m        tuple[AEVBState, AEVBInfo]: _description_\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     ((new_rec_params,new_rec_state), (new_gen_params, new_gen_state), new_opt_state), (loss_val, nll, kl) \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mtractable_kl_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrec_apply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgen_apply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AEVBState(new_rec_params, new_rec_state, new_gen_params, new_gen_state, new_opt_state), AEVBInfo(\n\u001b[1;32m    227\u001b[0m         loss_val, nll, kl\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/aevb/aevb/_src/core.py:97\u001b[0m, in \u001b[0;36mtractable_kl_step\u001b[0;34m(rng_key, rec_params, rec_state, gen_params, gen_state, opt_state, x, rec_apply_fn, gen_apply_fn, optimizer, n_samples)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, ((nll, kl), (new_rec_state, new_gen_state))\n\u001b[1;32m     96\u001b[0m loss_grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, argnums\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 97\u001b[0m (loss_val, ((nll, kl), (new_rec_state, new_gen_state))), (rec_grad, gen_grad) \u001b[38;5;241m=\u001b[39m \u001b[43mloss_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m (rec_updates, gen_updates), new_opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    100\u001b[0m     (rec_grad, gen_grad),\n\u001b[1;32m    101\u001b[0m     opt_state,\n\u001b[1;32m    102\u001b[0m     (rec_params, gen_params),\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m new_rec_params \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(rec_params, rec_updates)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aevb/aevb/_src/core.py:85\u001b[0m, in \u001b[0;36mtractable_kl_step.<locals>.loss_fn\u001b[0;34m(rec_params, gen_params)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(\n\u001b[1;32m     82\u001b[0m     rec_params: ArrayLikeTree, gen_params: ArrayLikeTree\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m---> 85\u001b[0m     (z_mu, z_sigma), new_rec_state \u001b[38;5;241m=\u001b[39m rec_apply_fn(params\u001b[38;5;241m=\u001b[39mrec_params, state\u001b[38;5;241m=\u001b[39mrec_state, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mx, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m     z_samples \u001b[38;5;241m=\u001b[39m reparameterized_sample(rng_key, z_mu, z_sigma, n_samples)\n\u001b[1;32m     87\u001b[0m     z \u001b[38;5;241m=\u001b[39m z_samples\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "aevb_state = init()\n",
    "\n",
    "step(random.key(2), aevb_state, jnp.ones((100, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dot_general requires contracting dimensions to have the same shape, got (3,) and (100,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m localtime, strftime\n\u001b[1;32m     56\u001b[0m now \u001b[38;5;241m=\u001b[39m strftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, localtime())\n\u001b[0;32m---> 57\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./samples-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnow\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 40\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(save_samples_pth)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, rng_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_keys):\n\u001b[1;32m     39\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(batches)\n\u001b[0;32m---> 40\u001b[0m     state, info \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m eval_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | nll: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo\u001b[38;5;241m.\u001b[39mnll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | kl: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo\u001b[38;5;241m.\u001b[39mkl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aevb/aevb/_src/core.py:212\u001b[0m, in \u001b[0;36mAEVB.<locals>.step_fn\u001b[0;34m(rng_key, aevb_state, x)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;129m@jit\u001b[39m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_fn\u001b[39m(rng_key, aevb_state, x) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[AEVBState, AEVBInfo]:\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Take a step of Algorithm 1 from [1] using the second verison of the\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    SGVB estimator which takes advantage of an analytical KL term when the prior\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    p(z) is a unit normal.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m        tuple[AEVBState, AEVBInfo]: _description_\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     ((new_rec_params,new_rec_state), (new_gen_params, new_gen_state), new_opt_state), (loss_val, nll, kl) \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mtractable_kl_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrec_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m            \u001b[49m\u001b[43maevb_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrec_apply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgen_apply\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AEVBState(new_rec_params, new_rec_state, new_gen_params, new_gen_state, new_opt_state), AEVBInfo(\n\u001b[1;32m    227\u001b[0m         loss_val, nll, kl\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/aevb/aevb/_src/core.py:97\u001b[0m, in \u001b[0;36mtractable_kl_step\u001b[0;34m(rng_key, rec_params, rec_state, gen_params, gen_state, opt_state, x, rec_apply_fn, gen_apply_fn, optimizer, n_samples)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, ((nll, kl), (new_rec_state, new_gen_state))\n\u001b[1;32m     96\u001b[0m loss_grad_fn \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, argnums\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 97\u001b[0m (loss_val, ((nll, kl), (new_rec_state, new_gen_state))), (rec_grad, gen_grad) \u001b[38;5;241m=\u001b[39m \u001b[43mloss_grad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m (rec_updates, gen_updates), new_opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    100\u001b[0m     (rec_grad, gen_grad),\n\u001b[1;32m    101\u001b[0m     opt_state,\n\u001b[1;32m    102\u001b[0m     (rec_params, gen_params),\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m new_rec_params \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(rec_params, rec_updates)\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aevb/aevb/_src/core.py:85\u001b[0m, in \u001b[0;36mtractable_kl_step.<locals>.loss_fn\u001b[0;34m(rec_params, gen_params)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(\n\u001b[1;32m     82\u001b[0m     rec_params: ArrayLikeTree, gen_params: ArrayLikeTree\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m---> 85\u001b[0m     (z_mu, z_sigma), new_rec_state \u001b[38;5;241m=\u001b[39m \u001b[43mrec_apply_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrec_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrec_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     z_samples \u001b[38;5;241m=\u001b[39m reparameterized_sample(rng_key, z_mu, z_sigma, n_samples)\n\u001b[1;32m     87\u001b[0m     z \u001b[38;5;241m=\u001b[39m z_samples\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/aevb/aevb/core.py:51\u001b[0m, in \u001b[0;36mwrap_eqx_model.<locals>.apply\u001b[0;34m(params, state, input, train)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m train:\n\u001b[1;32m     50\u001b[0m     model \u001b[38;5;241m=\u001b[39m eqx\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39minference_mode(model)\n\u001b[0;32m---> 51\u001b[0m out, updates \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, updates\n",
      "Cell \u001b[0;32mIn[2], line 51\u001b[0m, in \u001b[0;36mMlpDecoder.__call__\u001b[0;34m(self, x, state)\u001b[0m\n\u001b[1;32m     49\u001b[0m x \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#x, state = self.norm2(x, state)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aevb/.venv/lib/python3.11/site-packages/equinox/nn/_linear.py:91\u001b[0m, in \u001b[0;36mLinear.__call__\u001b[0;34m(self, x, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx must have scalar shape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m     x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mbroadcast_to(x, (\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m---> 91\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/aevb/.venv/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:736\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 736\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/aevb/.venv/lib/python3.11/site-packages/jax/_src/numpy/array_methods.py:264\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    262\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aevb/.venv/lib/python3.11/site-packages/jax/_src/numpy/lax_numpy.py:3413\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   3411\u001b[0m a \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(a, \u001b[38;5;28mtuple\u001b[39m(a_squeeze))\n\u001b[1;32m   3412\u001b[0m b \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39msqueeze(b, \u001b[38;5;28mtuple\u001b[39m(b_squeeze))\n\u001b[0;32m-> 3413\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3414\u001b[0m \u001b[43m  \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb_is_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3415\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_element_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_element_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3416\u001b[0m result \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mtranspose(out, perm)\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax_internal\u001b[38;5;241m.\u001b[39m_convert_element_type(result, preferred_element_type, output_weak_type)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/aevb/.venv/lib/python3.11/site-packages/jax/_src/lax/lax.py:2610\u001b[0m, in \u001b[0;36m_dot_general_shape_rule\u001b[0;34m(lhs, rhs, dimension_numbers, precision, preferred_element_type)\u001b[0m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mdefinitely_equal_shape(lhs_contracting_shape, rhs_contracting_shape):\n\u001b[1;32m   2608\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdot_general requires contracting dimensions to have the same \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2609\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2610\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(lhs_contracting_shape, rhs_contracting_shape))\n\u001b[1;32m   2612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _dot_general_shape_computation(lhs\u001b[38;5;241m.\u001b[39mshape, rhs\u001b[38;5;241m.\u001b[39mshape, dimension_numbers)\n",
      "\u001b[0;31mTypeError\u001b[0m: dot_general requires contracting dimensions to have the same shape, got (3,) and (100,)."
     ]
    }
   ],
   "source": [
    "# Main Function --------------------------------\n",
    "def main(save_samples_pth: str):\n",
    "\n",
    "    # Prepare Data\n",
    "    mnist_data = load_dataset(\"mnist\")\n",
    "    data_train = mnist_data[\"train\"]\n",
    "\n",
    "    X_train = np.stack([np.array(example[\"image\"]) for example in data_train])\n",
    "    X_train, N_train = prepare_data(X_train)\n",
    "\n",
    "    seed = 1\n",
    "    n = N_train.item()\n",
    "    batch_size = 100\n",
    "    batches = data_stream(seed, X_train, batch_size, n)\n",
    "\n",
    "    # Create AEVB inference engine\n",
    "    latent_dim = 3\n",
    "    optimizer = optax.adam(1e-3)\n",
    "\n",
    "    init, step, sample_data = AEVB(\n",
    "        latent_dim=latent_dim,\n",
    "        generative_model=(MlpEncoder, {}),\n",
    "        recognition_model=(MlpDecoder, {}),\n",
    "        optimizer=optimizer,\n",
    "        n_samples=15,\n",
    "        nn_lib=\"equinox\",\n",
    "    )\n",
    "\n",
    "    # Run AEVB\n",
    "    key = PRNGKey(1242)\n",
    "    num_steps = 10000\n",
    "    eval_every = 100\n",
    "\n",
    "    key, init_key = split(key)\n",
    "    state = init(init_key)\n",
    "\n",
    "    key, *training_keys = split(key, num_steps + 1)\n",
    "    for i, rng_key in enumerate(training_keys):\n",
    "        batch = next(batches)\n",
    "        state, info = step(rng_key, state, batch)\n",
    "        if i % eval_every == 0:\n",
    "            print(f\"Step {i} | loss: {info.loss} | nll: {info.nll} | kl: {info.kl}\")\n",
    "\n",
    "    # Random Data Samples of Learned Generative Model\n",
    "    key, data_samples_key = split(key)\n",
    "    samples, _ = sample_data(data_samples_key, state.gen_params, state.gen_state, 5)\n",
    "    fig, axs = plt.subplots(5, 1)\n",
    "    for i, s in enumerate(samples):\n",
    "        axs[i].imshow(s.reshape(28, 28))\n",
    "    plt.savefig(save_samples_pth, format=\"png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from time import localtime, strftime\n",
    "\n",
    "    now = strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n",
    "    main(f\"./samples-{now}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
